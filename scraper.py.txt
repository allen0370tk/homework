# scraper.py
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager
import re
import time
from typing import List, Dict

START_URL = "https://search.books.com.tw/search/query/key/LLM/cat/BKA"

def _clean_price(raw_text: str) -> int:
    if not raw_text:
        return 0
    # extract the largest continuous number in the string (likely the price)
    nums = re.findall(r"\d+", raw_text)
    if not nums:
        return 0
    # choose the largest numeric value found (helps if discount % also present)
    nums_int = [int(n) for n in nums]
    return max(nums_int)

def scrape_all_pages(timeout: int = 10) -> List[Dict]:
    """
    Returns a list of dicts: {title, author, price, link}
    """
    options = Options()
    options.add_argument("--headless=new")
    options.add_argument("--disable-gpu")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    driver = webdriver.Chrome(ChromeDriverManager().install(), options=options)
    wait = WebDriverWait(driver, timeout)

    results = []
    try:
        driver.get(START_URL)
        # 確保主要區塊載入
        wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, "div.table-searchbox")))
        while True:
            # 等待書籍 item 出現
            wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, "div.table-searchbox div.table-td")))
            items = driver.find_elements(By.CSS_SELECTOR, "div.table-searchbox div.table-td")
            for item in items:
                # title and link in h4 > a
                try:
                    a_tag = item.find_element(By.CSS_SELECTOR, "h4 a")
                    title = a_tag.text.strip()
                    link = a_tag.get_attribute("href") or ""
                except Exception:
                    title = "N/A"
                    link = ""
                # author: p.author a (may be multiple)
                try:
                    author_parent = item.find_element(By.CSS_SELECTOR, "p.author")
                    a_auths = author_parent.find_elements(By.CSS_SELECTOR, "a")
                    authors = [a.text.strip() for a in a_auths if a.text.strip()]
                    author = ", ".join(authors) if authors else "N/A"
                except Exception:
                    author = "N/A"
                # price: look for price text (may be inside p.price or span)
                price_val = 0
                try:
                    # common place: p.price or div.price
                    price_el = None
                    selectors = ["p.price", "div.price", "span.price", "p.item-price"]
                    for sel in selectors:
                        els = item.find_elements(By.CSS_SELECTOR, sel)
                        if els:
                            price_el = els[0]
                            break
                    raw_price = ""
                    if price_el:
                        raw_price = price_el.text
                    else:
                        # fallback: search any <b> text inside item for digits
                        b_el = item.find_elements(By.CSS_SELECTOR, "b")
                        if b_el:
                            raw_price = " ".join(b.text for b in b_el if b.text)
                    price_val = _clean_price(raw_price)
                except Exception:
                    price_val = 0

                results.append({
                    "title": title,
                    "author": author,
                    "price": price_val,
                    "link": link
                })

            # 嘗試找下一頁 <a> 標籤並點擊
            try:
                # 等下一頁按鈕可點擊
                next_btn = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, "a[title='下一頁']")))
                # 若此 <a> 有 disabled 或沒有 href，視為結尾
                href = next_btn.get_attribute("href")
                if not href or "javascript:void(0)" in href:
                    break
                # 等到可以點擊
                wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, "a[title='下一頁']")))
                # 點擊
                next_btn.click()
                # 小暫停，讓 DOM 重新載入（WebDriverWait 之後仍加短暫 sleep 以穩定）
                time.sleep(1)
                # 等待新頁的 table-searchbox 出現（避免與之前的內容混淆）
                wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, "div.table-searchbox")))
            except Exception:
                # 若找不到下一頁或不可點擊就結束
                break
    finally:
        driver.quit()

    return results

if __name__ == "__main__":
    books = scrape_all_pages()
    print(f"Scraped {len(books)} items")
    for b in books[:5]:
        print(b)